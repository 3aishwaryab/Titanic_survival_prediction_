{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment checks\n",
    "import os\n",
    "\n",
    "data_path = '../../data/processed/cleaned_titanic.csv'\n",
    "model_path = '../../backend/model.pkl'\n",
    "\n",
    "print('Data exists:', os.path.exists(data_path), '->', data_path)\n",
    "print('Model exists:', os.path.exists(model_path), '->', model_path)\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print('\\nCleaned data not found. Run: python scripts/prepare_data.py')\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print('\\nModel not found. Run: python scripts/train_model.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction Model\n",
    "\n",
    "This notebook implements a machine learning pipeline for predicting passenger survival on the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb977cf",
   "metadata": {},
   "source": [
    "## Model training and evaluation plan\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "1. Load the cleaned dataset produced by `01_data_cleaning.ipynb`.\n",
    "2. Create derived features (e.g., family size, titles, fare per person) that capture relevant passenger information.\n",
    "3. Train a Logistic Regression pipeline (preprocessing + classifier) as the primary model for its simplicity and interpretability.\n",
    "4. Evaluate the model using accuracy, confusion matrix, and ROC curve.\n",
    "5. Save the final pipeline to `backend/model.pkl` for use by the API consumer.\n",
    "\n",
    "Rationale: Logistic Regression provides a transparent baseline and is suitable for binary classification when features are preprocessed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                           confusion_matrix, roc_auc_score, roc_curve, auc)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "try:\n",
    "    # Load the cleaned data\n",
    "    df = pd.read_csv('../../data/processed/cleaned_titanic.csv')\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\")\n",
    "    print(\\\"\\nFirst few rows of the dataset:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nDataset statistics:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering and Preprocessing\n",
    "\n",
    "# Use shared create_features utility from backend so notebooks and backend share logic\n",
    "from backend.utils import create_features\n",
    "\n",
    "# Apply feature engineering\n",
    "df = create_features(df.copy())\n",
    "\n",
    "# Display new features\n",
    "print(\"New features created:\")\n",
    "display(df[['FamilySize', 'IsAlone', 'Title', 'AgeGroup', 'FarePerPerson']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Define features and target\n",
    "target = 'Survived'\n",
    "\n",
    "# Select features for modeling\n",
    "features = [\n",
    "    'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "    'Embarked', 'FamilySize', 'IsAlone', 'Title', 'AgeGroup', 'FarePerPerson'\n",
    "]\n",
    "\n",
    "# Separate features and target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Define preprocessing for numerical features\n",
    "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'FarePerPerson']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define preprocessing for categorical features\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'AgeGroup', 'IsAlone']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Save the feature names for later use\n",
    "feature_names = numeric_features.copy()\n",
    "for col in categorical_features:\n",
    "    if col in X_train.columns:\n",
    "        feature_names.extend([f\"{col}_{val}\" for val in sorted(X_train[col].dropna().unique())])\n",
    "\n",
    "# Save feature names\n",
    "os.makedirs('../../models', exist_ok=True)\n",
    "with open('../../models/feature_names.json', 'w') as f:\n",
    "    json.dump(feature_names, f)\n",
    "\n",
    "print(\"\\nPreprocessing pipeline created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a47c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "# Define primary model (Logistic Regression) and a short ensemble of candidates for comparison\n",
    "primary_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "other_models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train the primary pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', primary_model)\n",
    "])\n",
    "\n",
    "print(\"Training Logistic Regression pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optionally train other models for comparison (not saved as primary)\n",
    "results = {\n",
    "    'Logistic Regression': {'model': pipeline, 'accuracy': accuracy, 'roc_auc': roc_auc}\n",
    "}\n",
    "for name, model in other_models.items():\n",
    "    tmp = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    tmp.fit(X_train, y_train)\n",
    "    y_pred_tmp = tmp.predict(X_test)\n",
    "    y_proba_tmp = tmp.predict_proba(X_test)[:, 1]\n",
    "    results[name] = {\n",
    "        'model': tmp,\n",
    "        'accuracy': accuracy_score(y_test, y_pred_tmp),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba_tmp)\n",
    "    }\n",
    "    print(f\"{name}: Accuracy = {results[name]['accuracy']:.4f}, ROC AUC = {results[name]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf222eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison and Visualization\n",
    "\n",
    "# Compare model performance\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[model]['accuracy'] for model in results],\n",
    "    'ROC AUC': [results[model]['roc_auc'] for model in results]\n",
    "}).sort_values('ROC AUC', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "display(model_comparison)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['model'].predict_proba(X_test)[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for the best model (Random Forest)\n",
    "best_model_name = model_comparison.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "if hasattr(best_model.named_steps['classifier'], 'feature_importances_'):\n",
    "    # For tree-based models\n",
    "    importances = best_model.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Get feature names after one-hot encoding\n",
    "    try:\n",
    "        # For one-hot encoded features\n",
    "        ohe_columns = list(best_model.named_steps['preprocessor']\n",
    "                          .named_transformers_['cat']\n",
    "                          .named_steps['onehot']\n",
    "                          .get_feature_names_out(input_features=categorical_features))\n",
    "    except:\n",
    "        ohe_columns = []\n",
    "    \n",
    "    all_feature_names = numeric_features + ohe_columns\n",
    "    \n",
    "    # Create feature importance DataFrame\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': all_feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display top 10 features\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    display(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final Logistic Regression pipeline and metadata\n",
    "import json\n",
    "\n",
    "# Save the pipeline to the backend folder so consumer can load it\n",
    "os.makedirs('../../backend', exist_ok=True)\n",
    "model_path_backend = os.path.join('..', '..', 'backend', 'model.pkl')\n",
    "joblib.dump(pipeline, model_path_backend)\n",
    "print(f\"Model pipeline saved to {model_path_backend}\")\n",
    "\n",
    "# Save feature info (which raw fields are required in the API payload)\n",
    "feature_info = {\n",
    "    'required_raw_features': ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name'],\n",
    "    'training_features': features\n",
    "}\n",
    "feature_info_path = os.path.join('..', '..', 'backend', 'feature_info.json')\n",
    "with open(feature_info_path, 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "print(f\"Feature info saved to {feature_info_path}\")\n",
    "\n",
    "# Save a copy to models/ for record keeping\n",
    "os.makedirs('../../models', exist_ok=True)\n",
    "joblib.dump(pipeline, '../../models/titanic_survival_model.pkl')\n",
    "\n",
    "# Final evaluation on test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nFinal Model Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not Survived', 'Survived'],\n",
    "            yticklabels=['Not Survived', 'Survived'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training for Titanic Survival Prediction\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('../../models', exist_ok=True)\n",
    "\n",
    "# Load the cleaned data\n",
    "df = pd.read_csv('../../data/processed/cleaned_titanic.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(['Survived', 'Name', 'Ticket'], axis=1, errors='ignore')\n",
    "y = df['Survived']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Model Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Save the model\n",
    "model_path = '../../models/titanic_survival_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"\\nModel saved to {model_path}\")\n",
    "\n",
    "# Save feature names for later use\n",
    "feature_names = list(X.columns)\n",
    "joblib.dump(feature_names, '../../models/feature_names.pkl')\n",
    "print(\"Feature names saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
